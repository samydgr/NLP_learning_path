{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Predict the Countries from Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import get_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city1</th>\n",
       "      <th>country1</th>\n",
       "      <th>city2</th>\n",
       "      <th>country2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bern</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city1 country1    city2     country2\n",
       "0  Athens   Greece  Bangkok     Thailand\n",
       "1  Athens   Greece  Beijing        China\n",
       "2  Athens   Greece   Berlin      Germany\n",
       "3  Athens   Greece     Bern  Switzerland\n",
       "4  Athens   Greece    Cairo        Egypt"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('capitals.txt', delimiter=' ')\n",
    "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = pickle.load(open(\"word_embeddings_subset.p\", \"rb\"))\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension: [ 3.14941406e-02 -1.82617188e-01  1.63085938e-01  1.24511719e-01\n",
      " -1.85546875e-02 -1.73828125e-01 -1.21093750e-01 -1.32812500e-01\n",
      " -1.25000000e-01  2.45117188e-01 -2.18750000e-01  4.29687500e-02\n",
      "  1.66015625e-01 -1.14746094e-01 -7.37304688e-02  2.81982422e-02\n",
      "  7.71484375e-02  1.39648438e-01  1.06445312e-01  3.98437500e-01\n",
      "  3.18359375e-01 -3.34472656e-02  3.80859375e-02  2.15820312e-01\n",
      " -3.93676758e-03  4.95605469e-02 -1.81640625e-01 -1.77734375e-01\n",
      " -2.17773438e-01  2.28515625e-01  1.47460938e-01  2.80761719e-02\n",
      "  4.08935547e-03 -9.32617188e-02 -1.15722656e-01 -1.01318359e-02\n",
      " -3.69140625e-01 -1.53320312e-01  6.07910156e-02  1.50146484e-02\n",
      "  1.42578125e-01  4.63867188e-03  7.12890625e-02  2.69531250e-01\n",
      "  1.96289062e-01  6.73828125e-02  1.64794922e-03 -7.61718750e-02\n",
      " -8.15429688e-02  2.51953125e-01 -1.38671875e-01  2.61718750e-01\n",
      "  1.13525391e-02 -3.22265625e-02 -1.71875000e-01  1.67968750e-01\n",
      " -3.35937500e-01  8.10546875e-02 -1.99218750e-01  1.17187500e-01\n",
      " -2.94189453e-02  6.83593750e-02 -1.68945312e-01 -2.47070312e-01\n",
      "  2.60009766e-02 -1.35742188e-01  1.30859375e-01 -1.85546875e-01\n",
      " -2.03857422e-02  2.55126953e-02 -2.14843750e-01 -6.39648438e-02\n",
      " -6.98852539e-03  2.04101562e-01  2.84423828e-02  3.68652344e-02\n",
      "  1.25000000e-01 -1.23046875e-01 -1.58691406e-02  9.76562500e-02\n",
      "  1.46484375e-03  3.41796875e-02 -9.58251953e-03 -2.45117188e-01\n",
      "  3.14941406e-02 -8.34960938e-02 -2.57812500e-01  1.53320312e-01\n",
      "  2.14843750e-02  1.03515625e-01  2.16796875e-01 -1.95312500e-02\n",
      " -2.77343750e-01  1.28906250e-01 -3.71093750e-02  7.11059570e-03\n",
      "  1.69372559e-03 -2.87109375e-01  2.47070312e-01  1.36718750e-01\n",
      " -2.37304688e-01  4.17480469e-02 -7.81250000e-02  2.21679688e-01\n",
      "  1.81640625e-01 -7.81250000e-02 -2.54821777e-03 -2.65625000e-01\n",
      " -2.07519531e-02 -8.00781250e-02  1.31835938e-01  1.01074219e-01\n",
      "  2.26562500e-01 -1.92382812e-01  4.46777344e-02  6.64062500e-02\n",
      " -1.93359375e-01  1.08398438e-01  4.25781250e-01  2.55859375e-01\n",
      " -2.75878906e-02 -2.08984375e-01  1.44531250e-01 -1.61132812e-01\n",
      "  1.14257812e-01 -1.91406250e-01  1.24023438e-01 -1.61132812e-01\n",
      " -5.70312500e-01  1.08886719e-01 -1.89453125e-01 -4.56542969e-02\n",
      " -2.75390625e-01 -1.00585938e-01  5.63964844e-02 -2.37304688e-01\n",
      " -2.33398438e-01  1.22070312e-01  9.52148438e-02 -2.25585938e-01\n",
      " -3.68652344e-02 -2.00195312e-01 -7.61718750e-02 -3.97949219e-02\n",
      "  2.61718750e-01  2.44140625e-02  8.00781250e-02  3.93066406e-02\n",
      " -5.71289062e-02 -1.15234375e-01 -2.81982422e-02 -6.34765625e-02\n",
      " -1.95312500e-01 -1.78710938e-01  1.21093750e-01 -1.35742188e-01\n",
      " -4.39453125e-01  4.58984375e-02  4.76074219e-02  2.86865234e-02\n",
      "  2.06298828e-02  3.04687500e-01  3.78417969e-02 -7.37304688e-02\n",
      "  2.75390625e-01 -2.02636719e-02  2.95410156e-02  8.17871094e-03\n",
      " -7.66601562e-02  9.66796875e-02 -2.09960938e-01  1.23046875e-01\n",
      "  1.71875000e-01 -1.55029297e-02 -1.05468750e-01 -4.76074219e-02\n",
      "  9.42382812e-02 -1.46484375e-01  1.87988281e-02 -2.39257812e-02\n",
      " -1.94335938e-01 -2.89062500e-01 -2.87109375e-01 -4.37011719e-02\n",
      "  2.53906250e-01 -2.01171875e-01  1.61132812e-01  1.73950195e-03\n",
      " -6.98242188e-02  1.50390625e-01 -7.12890625e-02  5.73730469e-02\n",
      "  1.08642578e-02  2.28271484e-02 -4.29687500e-02  3.51562500e-01\n",
      "  9.66796875e-02 -1.11328125e-01 -1.28906250e-01 -2.21679688e-01\n",
      "  9.22851562e-02 -1.06933594e-01 -1.41601562e-01 -4.15039062e-02\n",
      "  1.72851562e-01 -1.26953125e-01 -4.49218750e-02 -6.29882812e-02\n",
      "  4.54101562e-02 -1.72851562e-01  1.01074219e-01 -1.98242188e-01\n",
      " -1.58203125e-01  1.42578125e-01 -1.66015625e-01 -9.71679688e-02\n",
      " -2.05078125e-02 -2.42187500e-01 -6.54296875e-02  8.15429688e-02\n",
      "  9.17968750e-02 -2.67578125e-01 -1.59179688e-01 -1.36718750e-01\n",
      " -4.27734375e-01 -9.76562500e-02  1.36718750e-01  1.64062500e-01\n",
      "  3.71093750e-01 -3.49121094e-02 -2.10937500e-01 -9.66796875e-02\n",
      "  4.85839844e-02  6.78710938e-02 -3.22265625e-02 -2.02636719e-02\n",
      " -7.81250000e-02  8.74023438e-02  1.96533203e-02 -8.74023438e-02\n",
      " -5.37109375e-02 -1.05957031e-01  1.50390625e-01  4.49218750e-02\n",
      " -8.15429688e-02 -2.80761719e-02 -1.55273438e-01 -1.77734375e-01\n",
      " -1.35742188e-01  5.54199219e-02  2.40234375e-01 -7.86781311e-05\n",
      "  6.15234375e-02  1.82617188e-01  1.40625000e-01  5.66406250e-02\n",
      "  1.19140625e-01  6.49414062e-02 -6.05468750e-02 -4.49218750e-02\n",
      "  1.30859375e-01  1.76757812e-01  8.54492188e-02  1.73339844e-02\n",
      "  1.71875000e-01  1.63574219e-02 -2.61718750e-01 -1.73828125e-01\n",
      "  1.63574219e-02 -9.70458984e-03 -1.60156250e-01  3.75000000e-01\n",
      "  2.69531250e-01 -5.98144531e-02  2.01171875e-01 -7.08007812e-03\n",
      " -1.96289062e-01  2.79541016e-02 -2.27539062e-01  2.34375000e-02\n",
      " -1.53320312e-01 -4.51660156e-02 -3.08837891e-02 -1.51367188e-01\n",
      " -2.17773438e-01 -1.34277344e-02 -2.51464844e-02 -2.19726562e-02\n",
      " -1.04980469e-01  2.04101562e-01  1.07421875e-01  2.15820312e-01\n",
      "  1.48437500e-01  1.15234375e-01 -1.76757812e-01  1.44531250e-01\n",
      " -1.35742188e-01  3.75976562e-02  1.96289062e-01  1.79687500e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"dimension: {}\".format(word_embeddings['Spain']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cosine Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    dot = np.dot(A,B)\n",
    "    norma = np.sqrt(np.dot(A,A))\n",
    "    normb = np.sqrt(np.dot(B,B))\n",
    "    cos = dot / (norma*normb) \n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510956"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king = word_embeddings['king']\n",
    "queen = word_embeddings['queen']\n",
    "\n",
    "cosine_similarity(king, queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(A, B):\n",
    "    d = np.linalg.norm(A-B)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4796925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean(king, queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Finding the country of each capital\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(city1, country1, city2, embeddings):\n",
    "    group = set((city1, country1, city2))\n",
    "    city1_emb = word_embeddings[city1]\n",
    "\n",
    "    country1_emb = word_embeddings[country1]\n",
    "    city2_emb = word_embeddings[city2]\n",
    "    vec = country1_emb - city1_emb + city2_emb \n",
    "    similarity = -1\n",
    "    country = ''\n",
    "    for word in embeddings.keys():\n",
    "        if word not in group:\n",
    "            word_emb = word_embeddings[word]\n",
    "            cur_similarity = cosine_similarity(vec,word_emb)\n",
    "\n",
    "            if cur_similarity > similarity:\n",
    "                similarity = cur_similarity\n",
    "                country = (word, similarity)\n",
    "\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Iran', 0.8067936)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing your function, note to make it more robust you can return the 5 most similar words.\n",
    "get_country('Athens', 'Greece', 'Tehran', word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(word_embeddings, data):\n",
    "    num_correct = 0\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "\n",
    "        city1 = row['city1']\n",
    "        country1 = row['country1']\n",
    "        city2 =  row['city2']\n",
    "        country2 = row['country2']\n",
    "        predicted_country2, _ = get_country(city1,country1,city2,word_embeddings)\n",
    "        if predicted_country2 == country2:\n",
    "            num_correct += 1\n",
    "    m = len(data)\n",
    "    accuracy = num_correct/m\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.92\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(word_embeddings, data)\n",
    "print(f\"Accuracy is {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "NLPC1-3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
